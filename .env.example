PRIVATE_KEY= # ainetwork private key
BLOCKCHAIN_NETWORK= # 1 or 0
MODEL_URL= # this server endpoint url
INFERENCE_URL= # inference server endpoint url
MODEL_NAME= # model name (ex: meta-llama/Llama-3.2-11B-Vision-Instruct)
API_KEY= # optional api key for accessing to your inference url
PORT= # server port